{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb59ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from collections import defaultdict\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.prediction_algorithms.knns import KNNBaseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a3ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "item_cols = ['item_id', 'movie', 'release_date', 'v_release_date', 'imdb_url', 'unknown', 'action', \n",
    "             'adventure', 'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
    "             'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi','Thriller', 'War', 'Western']\n",
    "\n",
    "trainDf = pd.read_csv('../data/MovieLens.training', sep='\\t', lineterminator='\\n')\n",
    "testDf = pd.read_csv('../data/MovieLens.test', sep='\\t', lineterminator='\\n')\n",
    "itemDf = pd.read_csv('../data/MovieLens.item', sep='|', lineterminator='\\n')\n",
    "\n",
    "trainDf.columns = train_cols\n",
    "testDf.columns = train_cols\n",
    "itemDf.columns = item_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9ae50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_data = Dataset.load_from_df(trainDf[['user_id', 'item_id', 'rating']], reader)\n",
    "test_data = Dataset.load_from_df(testDf[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7adf7125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(df, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        test_df(list of Prediction objects): dataframe with predictions.\n",
    "        n(int): The number of recommendation to output for each user. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [raw item id, ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for index, row in df.iterrows():\n",
    "        top_n[row[\"user_id\"]].append((row['item_id'], row['prediction']))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_items = [item_rating_t[0] for item_rating_t in user_ratings[:n]]\n",
    "        top_n[uid] = top_items\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491120b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - get filler items\n",
    "from random import randrange\n",
    "rating_mean, rating_std = trainDf.rating.mean(), trainDf.rating.std()\n",
    "\n",
    "class FakeProfile(object): \n",
    "    MAX_RATING = 5\n",
    "    \n",
    "    def __init__(self, target_items, \n",
    "                 filler_item_count = 70):\n",
    "        self.target_items  = target_items\n",
    "        self.filler_item_count = filler_item_count\n",
    "        self.selected_items = {}\n",
    "        self.filler_items = {}\n",
    "        \n",
    "    def setSelectedItems(self, selectedItems):\n",
    "        #selectedItems = freqRatedItems[np.random.choice(len(freqRatedItems), size=self.selected_items_count, replace=False)]\n",
    "        for item in selectedItems:\n",
    "            self.selected_items[item] = self.MAX_RATING\n",
    "    \n",
    "    def fillerItems(self, selectedItems):\n",
    "        targetSelItems = list(self.target_items)\n",
    "        targetSelItems.extend(selectedItems)\n",
    "        #print(targetSelItems)\n",
    "        fillers_candidates = list(set(trainDf.item_id.unique()) - set(targetSelItems) )\n",
    "        fillers = np.random.choice(fillers_candidates, size=self.filler_item_count, replace=False)\n",
    "        ratings = np.round(np.random.normal(loc=rating_mean, scale=rating_std, size=self.filler_item_count), 1)\n",
    "        for item, rating in zip(fillers, ratings):\n",
    "            self.filler_items[item] = rating\n",
    "                \n",
    "    def create(self, selectedItems):\n",
    "        self.setSelectedItems(selectedItems)\n",
    "        self.fillerItems(selectedItems)\n",
    "        \n",
    "    def print(self):\n",
    "        print(f'target_item : {self.target_items}')\n",
    "        print(f'selected_items : {self.selected_items}')\n",
    "        print(f'filler_items : {self.filler_items}')\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    def getAllItemRatings(self):\n",
    "        itemRatings = [(item, self.MAX_RATING) for item in self.target_items]\n",
    "        for item in self.selected_items:\n",
    "            itemRatings.append((item, self.selected_items[item]))\n",
    "        for item in self.filler_items:\n",
    "            itemRatings.append((item, self.filler_items[item]))\n",
    "        return itemRatings\n",
    "    \n",
    "def createProfiles(targetItems, selected_items, n):\n",
    "    fake_profiles = []\n",
    "    for _ in range(n):\n",
    "        fp = FakeProfile(targetItems)\n",
    "        fp.create(selected_items)\n",
    "        fake_profiles.append(fp)\n",
    "    \n",
    "    '''\n",
    "    # - Uncomment to print\n",
    "    for fp in fake_profiles:\n",
    "        fp.print()\n",
    "    '''\n",
    "    return fake_profiles\n",
    " \n",
    "def createProfilesAsDf(targetItems, selected_items, n):\n",
    "    fake_profiles = createProfiles(targetItems, selected_items, n)\n",
    "    userId = 1100\n",
    "    timestamp = 874965758\n",
    "    fakeRatingsdata = {'userId': [], 'item_id': [], 'ratings': [], 'timestamp': []}\n",
    "    for fp in fake_profiles:\n",
    "        userId += 1\n",
    "        itemRatings = fp.getAllItemRatings()\n",
    "        for itemRatingPair in itemRatings:\n",
    "            fakeRatingsdata['userId'].append(userId)\n",
    "            fakeRatingsdata['item_id'].append(itemRatingPair[0])\n",
    "            fakeRatingsdata['ratings'].append(itemRatingPair[1])\n",
    "            fakeRatingsdata['timestamp'].append(timestamp)\n",
    "\n",
    "    columnsZipped = zip(fakeRatingsdata['userId'], fakeRatingsdata['item_id'],\n",
    "                       fakeRatingsdata['ratings'], fakeRatingsdata['timestamp'])\n",
    "    fakeProfileDf = pd.DataFrame(list(columnsZipped),\n",
    "                   columns =['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    return fakeProfileDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0350d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_shift(predBefore, predAtk, target_users, testDf):\n",
    "    \n",
    "    targetUsersTest = testDf[testDf.user_id.isin(target_users)]\n",
    "    numTargetUsersInTest = len(targetUsersTest.user_id)\n",
    "    print(f'Number of target users in test: {numTargetUsersInTest}, uniq: {len(targetUsersTest.user_id.unique())}')\n",
    "    \n",
    "    # - Prediction shift across targetted users\n",
    "    predAttackTargetUser = predAtk[predAtk.user_id.isin(target_users)].sort_values(['user_id', 'item_id']).prediction\n",
    "    predTargetUser = predBefore[predBefore.user_id.isin(target_users)].sort_values(['user_id', 'item_id']).prediction\n",
    "    targetUserPredShift = np.sum(predAttackTargetUser - predTargetUser)/numTargetUsersInTest\n",
    "    \n",
    "    predAfterAttack = predAtk.sort_values(['user_id', 'item_id']).prediction\n",
    "    predBeforeAttack = predBefore.sort_values(['user_id', 'item_id']).prediction\n",
    "    print('diff sum: ', np.sum(predAfterAttack - predBeforeAttack))\n",
    "    print('count: ', testDf.user_id.count(), ' uniq: ', len(testDf.user_id.unique()))\n",
    "    allUsersPredShift = np.sum(predAfterAttack - predBeforeAttack)/len(testDf.user_id)\n",
    "    \n",
    "    return (allUsersPredShift, targetUserPredShift)\n",
    "\n",
    "def filterRecsByTargetItem(recommendations, targetItems):\n",
    "    recWithTargetItems = {}\n",
    "    for user_id in recommendations.keys():\n",
    "        topNRec = recommendations[user_id]\n",
    "        is_target_item_present = any(item in topNRec for item in targetItems)\n",
    "        if is_target_item_present:\n",
    "            recWithTargetItems[user_id] = topNRec\n",
    "            #print(user_id, topNRec)\n",
    "    \n",
    "    return recWithTargetItems\n",
    "\n",
    "def getHitRatioPerItem(topNRecAllUsers, targetItems):\n",
    "    hitRatioAllItems = {}\n",
    "    \n",
    "    for item in targetItems:\n",
    "        usersWithItem = 0\n",
    "        for user in topNRecAllUsers.keys():\n",
    "            if item in topNRecAllUsers[user]:\n",
    "                usersWithItem += 1\n",
    "        hitRatio_i = usersWithItem/(len(topNRecAllUsers.keys()) * 1.0)\n",
    "        hitRatioAllItems[item] = hitRatio_i\n",
    "                                    \n",
    "    return hitRatioAllItems \n",
    "\n",
    "def getAvgHitRatio(hitRatioPerItem):\n",
    "    sumHitRatio = 0\n",
    "    for hitRatio_i in hitRatioPerItem.values():\n",
    "        sumHitRatio += hitRatio_i \n",
    "    return sumHitRatio/(len(hitRatioPerItem.keys()) * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8cda4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of target users:  190\n",
      "target_users:  190\n"
     ]
    }
   ],
   "source": [
    "NUM_SEL_ITEMS = 3\n",
    "NUM_FILLER_ITEMS = 90\n",
    "selected_items = [ 50, 181, 258]\n",
    "target_items = [868, 1162, 927, 1521, 1301, 1191]\n",
    "\n",
    "def getTargetUsers(targetItems):\n",
    "    users_rated_target = set(trainDf[trainDf.item_id.isin(targetItems)].user_id.values)\n",
    "    # - Users who have not rated target item\n",
    "    data_tmp = trainDf[~trainDf.user_id.isin(users_rated_target)].copy()\n",
    "\n",
    "    # - Users who have not rated target item and have rated selected_items\n",
    "    target_users = data_tmp[data_tmp.item_id.isin(selected_items)].groupby('user_id').size()\n",
    "    \n",
    "    print(\"Number of target users: \", \n",
    "           target_users[(target_users == NUM_SEL_ITEMS)].shape[0])\n",
    "    target_users = sorted(target_users[(target_users == NUM_SEL_ITEMS)].index)\n",
    "    return target_users\n",
    "\n",
    "target_users = getTargetUsers(target_items)\n",
    "print(\"target_users: \", len(target_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fa654",
   "metadata": {},
   "source": [
    "### Attack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d8d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FAKE_USERS = 50\n",
    "attackDataDf = createProfilesAsDf(target_items, selected_items, NUM_FAKE_USERS)\n",
    "attackTrainData = pd.concat([trainDf, attackDataDf]).sort_values(by=['user_id', 'item_id'])\n",
    "attacktrain_data = Dataset.load_from_df(attackTrainData[['user_id', 'item_id', 'rating']], reader)\n",
    "attackTrainset = attacktrain_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf793a64",
   "metadata": {},
   "source": [
    "### User based KNN recommender system model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e8a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# - https://surprise.readthedocs.io/en/stable/getting_started.html?highlight=KNNBaseline#use-a-custom-dataset\n",
    "userBasedKNN = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "userBasedKNN.fit(trainset)\n",
    "b4TestDf = testDf.copy()\n",
    "\n",
    "prediction = []\n",
    "for index, row in b4TestDf.iterrows():\n",
    "    pred = userBasedKNN.predict(row[\"user_id\"], row[\"item_id\"], row[\"rating\"], verbose=False)\n",
    "    prediction.append(pred[3])\n",
    "#print('b4 prediction: ', prediction)\n",
    "    \n",
    "b4TestDf['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e726bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  1.0  :  [114.0, 64.0, 272.0, 174.0, 98.0, 134.0, 100.0, 12.0, 190.0, 56.0]\n",
      "User  2.0  :  [50.0, 313.0, 251.0, 19.0, 315.0, 316.0, 297.0, 303.0, 257.0, 298.0]\n",
      "User  3.0  :  [318.0, 272.0, 345.0, 307.0, 300.0, 328.0, 327.0, 332.0, 331.0, 343.0]\n",
      "User  4.0  :  [50.0, 357.0, 303.0, 354.0, 288.0, 361.0, 294.0, 356.0, 264.0, 260.0]\n",
      "User  5.0  :  [173.0, 89.0, 445.0, 176.0, 100.0, 1.0, 98.0, 42.0, 79.0, 185.0]\n",
      "User  6.0  :  [480.0, 318.0, 483.0, 515.0, 513.0, 488.0, 528.0, 479.0, 187.0, 134.0]\n",
      "User  7.0  :  [174.0, 223.0, 127.0, 511.0, 483.0, 661.0, 182.0, 543.0, 185.0, 657.0]\n",
      "User  8.0  :  [50.0, 172.0, 127.0, 183.0, 79.0, 651.0, 511.0, 210.0, 190.0, 89.0]\n",
      "User  9.0  :  [487.0, 479.0, 527.0, 521.0, 691.0, 298.0, 507.0, 340.0, 6.0, 286.0]\n",
      "User  10.0  :  [483.0, 474.0, 127.0, 98.0, 603.0, 488.0, 493.0, 56.0, 100.0, 199.0]\n",
      "User  11.0  :  [190.0, 100.0, 735.0, 12.0, 524.0, 191.0, 194.0, 22.0, 736.0, 740.0]\n",
      "User  12.0  :  [318.0, 50.0, 196.0, 172.0, 96.0, 28.0, 191.0, 735.0, 204.0, 82.0]\n",
      "User  13.0  :  [868.0, 318.0, 480.0, 483.0, 694.0, 524.0, 787.0, 64.0, 601.0, 181.0]\n",
      "User  14.0  :  [174.0, 474.0, 408.0, 922.0, 357.0, 50.0, 603.0, 519.0, 98.0, 498.0]\n",
      "User  15.0  :  [127.0, 889.0, 1.0, 459.0, 7.0, 286.0, 137.0, 274.0, 924.0, 9.0]\n"
     ]
    }
   ],
   "source": [
    "top10B4 = get_top_n(b4TestDf)\n",
    "for user in top10B4.keys():\n",
    "    if user < 16:\n",
    "        print(\"User \", user, \" : \", top10B4[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46576667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "attackUserBasedKNN = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "attackUserBasedKNN.fit(attackTrainset)\n",
    "attackTestDf = testDf.copy()\n",
    "\n",
    "prediction = []\n",
    "for index, row in attackTestDf.iterrows():\n",
    "    pred = attackUserBasedKNN.predict(row[\"user_id\"], row[\"item_id\"], row[\"rating\"], verbose=False)\n",
    "    prediction.append(pred[3])\n",
    "    \n",
    "attackTestDf['prediction'] = prediction\n",
    "#print('prediction after: ', prediction)\n",
    "attackTop10 = get_top_n(attackTestDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f184a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  1.0  :  [114.0, 64.0, 272.0, 174.0, 100.0, 98.0, 12.0, 134.0, 190.0, 56.0]\n",
      "User  2.0  :  [50.0, 313.0, 251.0, 19.0, 315.0, 316.0, 297.0, 303.0, 257.0, 298.0]\n",
      "User  3.0  :  [318.0, 272.0, 345.0, 307.0, 300.0, 328.0, 331.0, 332.0, 327.0, 343.0]\n",
      "User  4.0  :  [50.0, 357.0, 303.0, 354.0, 288.0, 361.0, 294.0, 356.0, 264.0, 260.0]\n",
      "User  5.0  :  [173.0, 89.0, 176.0, 100.0, 1.0, 98.0, 42.0, 79.0, 185.0, 429.0]\n",
      "User  6.0  :  [480.0, 318.0, 483.0, 515.0, 488.0, 479.0, 528.0, 513.0, 134.0, 187.0]\n",
      "User  7.0  :  [174.0, 223.0, 127.0, 511.0, 483.0, 185.0, 661.0, 657.0, 166.0, 182.0]\n",
      "User  8.0  :  [50.0, 172.0, 127.0, 183.0, 651.0, 79.0, 511.0, 210.0, 190.0, 89.0]\n",
      "User  9.0  :  [479.0, 487.0, 527.0, 521.0, 691.0, 298.0, 507.0, 340.0, 6.0, 286.0]\n",
      "User  10.0  :  [483.0, 474.0, 127.0, 603.0, 98.0, 488.0, 199.0, 100.0, 56.0, 493.0]\n",
      "User  11.0  :  [190.0, 100.0, 735.0, 191.0, 12.0, 194.0, 524.0, 736.0, 22.0, 740.0]\n",
      "User  12.0  :  [318.0, 50.0, 172.0, 196.0, 96.0, 28.0, 191.0, 735.0, 204.0, 82.0]\n",
      "User  13.0  :  [868.0, 766.0, 318.0, 480.0, 483.0, 181.0, 64.0, 524.0, 694.0, 173.0]\n",
      "User  14.0  :  [174.0, 474.0, 408.0, 922.0, 357.0, 50.0, 603.0, 98.0, 519.0, 498.0]\n",
      "User  15.0  :  [127.0, 889.0, 1.0, 459.0, 7.0, 274.0, 137.0, 924.0, 591.0, 286.0]\n"
     ]
    }
   ],
   "source": [
    "for user in attackTop10.keys():\n",
    "    if user < 16:\n",
    "        print(\"User \", user, \" : \", attackTop10[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92ba4955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of target users in test: 2228, uniq: 40\n",
      "diff sum:  58.2863687449364\n",
      "count:  19999  uniq:  459\n",
      "Prediction shift - Target users:  0.0006773320921356566\n",
      "Prediction shift - All users:  0.0029144641604548424\n"
     ]
    }
   ],
   "source": [
    "allUsersPredShift, targetUserPredShift = prediction_shift(b4TestDf, attackTestDf, target_users, testDf)\n",
    "print(\"Prediction shift - Target users: \", targetUserPredShift)\n",
    "print(\"Prediction shift - All users: \", allUsersPredShift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c53cd9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with targets: 6\n",
      "Number of users with targets before attack: 2\n",
      "hitRatioPerItem:  {868: 0.004357298474945534, 1162: 0.002178649237472767, 927: 0.004357298474945534, 1521: 0.002178649237472767, 1301: 0.0, 1191: 0.0}\n",
      "\n",
      "avgHitRatio after attack:  0.002178649237472767\n"
     ]
    }
   ],
   "source": [
    "topNRecAllUsersWithTargetsB4 = filterRecsByTargetItem(top10B4, target_items)\n",
    "topNRecAllUsersWithTargets = filterRecsByTargetItem(attackTop10, target_items)\n",
    "\n",
    "print(f'Number of users with targets: {len(topNRecAllUsersWithTargets)}')\n",
    "print(f'Number of users with targets before attack: {len(topNRecAllUsersWithTargetsB4)}')\n",
    "\n",
    "hitRatioPerItem = getHitRatioPerItem(attackTop10, target_items)\n",
    "print(\"hitRatioPerItem: \", hitRatioPerItem)\n",
    "avgHitRatio = getAvgHitRatio(hitRatioPerItem)\n",
    "print(\"\\navgHitRatio after attack: \", avgHitRatio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac5166",
   "metadata": {},
   "source": [
    "### Item based KNN recommender system model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c221822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "itemBasedKNN = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "itemBasedKNN.fit(trainset)\n",
    "\n",
    "itemTestDf = testDf.copy()\n",
    "prediction = []\n",
    "\n",
    "for index, row in itemTestDf.iterrows():\n",
    "    pred = itemBasedKNN.predict(row[\"user_id\"], row[\"item_id\"], row[\"rating\"], verbose=False)\n",
    "    prediction.append(pred[3])\n",
    "    \n",
    "itemTestDf['prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "965a7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  1.0  :  [170.0, 174.0, 272.0, 64.0, 134.0, 100.0, 12.0, 60.0, 190.0, 98.0]\n",
      "User  2.0  :  [50.0, 315.0, 251.0, 19.0, 313.0, 297.0, 316.0, 303.0, 292.0, 298.0]\n",
      "User  3.0  :  [318.0, 345.0, 272.0, 307.0, 331.0, 354.0, 348.0, 335.0, 327.0, 334.0]\n",
      "User  4.0  :  [303.0, 357.0, 361.0, 50.0, 354.0, 288.0, 356.0, 260.0, 264.0, 294.0]\n",
      "User  5.0  :  [89.0, 176.0, 173.0, 100.0, 144.0, 1.0, 79.0, 69.0, 109.0, 429.0]\n",
      "User  6.0  :  [483.0, 515.0, 318.0, 513.0, 488.0, 357.0, 134.0, 480.0, 478.0, 199.0]\n",
      "User  7.0  :  [643.0, 483.0, 174.0, 172.0, 223.0, 657.0, 528.0, 8.0, 127.0, 191.0]\n",
      "User  8.0  :  [50.0, 511.0, 183.0, 172.0, 79.0, 176.0, 127.0, 651.0, 89.0, 190.0]\n",
      "User  9.0  :  [479.0, 527.0, 487.0, 521.0, 340.0, 298.0, 507.0, 6.0, 691.0, 286.0]\n",
      "User  10.0  :  [483.0, 603.0, 98.0, 474.0, 64.0, 127.0, 191.0, 488.0, 199.0, 651.0]\n",
      "User  11.0  :  [190.0, 735.0, 191.0, 216.0, 12.0, 22.0, 100.0, 194.0, 429.0, 736.0]\n",
      "User  12.0  :  [50.0, 196.0, 318.0, 735.0, 28.0, 282.0, 172.0, 143.0, 96.0, 15.0]\n",
      "User  13.0  :  [480.0, 483.0, 185.0, 519.0, 180.0, 524.0, 530.0, 488.0, 178.0, 651.0]\n",
      "User  14.0  :  [603.0, 519.0, 474.0, 498.0, 357.0, 98.0, 408.0, 313.0, 50.0, 174.0]\n",
      "User  15.0  :  [127.0, 286.0, 459.0, 1.0, 7.0, 889.0, 864.0, 222.0, 20.0, 148.0]\n"
     ]
    }
   ],
   "source": [
    "topItem10 = get_top_n(itemTestDf)\n",
    "for user in topItem10.keys():\n",
    "    if user < 16:\n",
    "        print(\"User \", user, \" : \", topItem10[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c886165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "attackItemBasedKNN = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "attackItemBasedKNN.fit(attackTrainset)\n",
    "attackTestDf = testDf.copy()\n",
    "\n",
    "prediction = []\n",
    "for index, row in attackTestDf.iterrows():\n",
    "    pred = attackItemBasedKNN.predict(row[\"user_id\"], row[\"item_id\"], row[\"rating\"], verbose=False)\n",
    "    prediction.append(pred[3])\n",
    "    \n",
    "attackTestDf['prediction'] = prediction\n",
    "#print('prediction after: ', prediction)\n",
    "attackItemTop10 = get_top_n(attackTestDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "080808cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of target users in test: 2228, uniq: 40\n",
      "diff sum:  642.2561006161402\n",
      "count:  19999  uniq:  459\n",
      "Prediction shift - Target users:  0.024533410919141473\n",
      "Prediction shift - All users:  0.03211441075134458\n"
     ]
    }
   ],
   "source": [
    "allUsersPredShift, targetUserPredShift = prediction_shift(b4TestDf, attackTestDf, target_users, testDf)\n",
    "print(\"Prediction shift - Target users: \", targetUserPredShift)\n",
    "print(\"Prediction shift - All users: \", allUsersPredShift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3ba3f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users with targets: 5\n",
      "Number of users with targets before attack: 0\n",
      "hitRatioPerItem:  {868: 0.004357298474945534, 1162: 0.004357298474945534, 927: 0.0, 1521: 0.002178649237472767, 1301: 0.0, 1191: 0.0}\n",
      "\n",
      "avgHitRatio after attack:  0.0018155410312273058\n"
     ]
    }
   ],
   "source": [
    "topNRecAllUsersWithTargetsB4 = filterRecsByTargetItem(topItem10, target_items)\n",
    "topNRecAllUsersWithTargets = filterRecsByTargetItem(attackItemTop10, target_items)\n",
    "\n",
    "print(f'Number of users with targets: {len(topNRecAllUsersWithTargets)}')\n",
    "print(f'Number of users with targets before attack: {len(topNRecAllUsersWithTargetsB4)}')\n",
    "\n",
    "hitRatioPerItem = getHitRatioPerItem(attackItemTop10, target_items)\n",
    "print(\"hitRatioPerItem: \", hitRatioPerItem)\n",
    "avgHitRatio = getAvgHitRatio(hitRatioPerItem)\n",
    "print(\"\\navgHitRatio after attack: \", avgHitRatio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
