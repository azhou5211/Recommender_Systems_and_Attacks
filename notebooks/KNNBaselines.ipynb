{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb59ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from collections import defaultdict\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.prediction_algorithms.knns import KNNBaseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27a3ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "item_cols = ['item_id', 'movie', 'release_date', 'v_release_date', 'imdb_url', 'unknown', 'action', \n",
    "             'adventure', 'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
    "             'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi','Thriller', 'War', 'Western']\n",
    "\n",
    "train_df = pd.read_csv('../data/MovieLens.training', sep='\\t', lineterminator='\\n')\n",
    "test_df = pd.read_csv('../data/MovieLens.test', sep='\\t', lineterminator='\\n')\n",
    "item_df = pd.read_csv('../data/MovieLens.item', sep='|', lineterminator='\\n')\n",
    "\n",
    "train_df.columns = train_cols\n",
    "test_df.columns = train_cols\n",
    "item_df.columns = item_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd9ae50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_data = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "test_data = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7adf7125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(df, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        test_df(list of Prediction objects): dataframe with predictions.\n",
    "        n(int): The number of recommendation to output for each user. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [raw item id, ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for index, row in df.iterrows():\n",
    "        top_n[row[\"user_id\"]].append((row['item_id'], row['predictions']))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_items = [item_rating_t[0] for item_rating_t in user_ratings[:n]]\n",
    "        top_n[uid] = top_items\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf793a64",
   "metadata": {},
   "source": [
    "### User based KNN recommender system model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2e8a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# - https://surprise.readthedocs.io/en/stable/getting_started.html?highlight=KNNBaseline#use-a-custom-dataset\n",
    "sim_options_user = {'name': 'pearson_baseline', 'user_based': True}\n",
    "\n",
    "userBasedKNN = KNNBaseline(sim_options=sim_options_user)\n",
    "userBasedKNN.fit(trainset)\n",
    "\n",
    "prediction = []\n",
    "for index, row in test_df.iterrows():\n",
    "    pred = userBasedKNN.predict(row[\"user_id\"], row[\"item_id\"], row[\"rating\"], verbose=False)\n",
    "    prediction.append(pred[3])\n",
    "    \n",
    "test_df['predictions'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9e726bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  1.0  :  [114.0, 64.0, 272.0, 174.0, 98.0, 134.0, 100.0, 12.0, 190.0, 56.0]\n",
      "User  2.0  :  [50.0, 313.0, 251.0, 19.0, 315.0, 316.0, 297.0, 303.0, 257.0, 298.0]\n",
      "User  3.0  :  [318.0, 272.0, 345.0, 307.0, 300.0, 328.0, 327.0, 332.0, 331.0, 343.0]\n",
      "User  4.0  :  [50.0, 357.0, 303.0, 354.0, 288.0, 361.0, 294.0, 356.0, 264.0, 260.0]\n",
      "User  5.0  :  [173.0, 89.0, 445.0, 176.0, 100.0, 1.0, 98.0, 42.0, 79.0, 185.0]\n",
      "User  6.0  :  [480.0, 318.0, 483.0, 515.0, 513.0, 488.0, 528.0, 479.0, 187.0, 134.0]\n",
      "User  7.0  :  [174.0, 223.0, 127.0, 511.0, 483.0, 661.0, 182.0, 543.0, 185.0, 657.0]\n",
      "User  8.0  :  [50.0, 172.0, 127.0, 183.0, 79.0, 651.0, 511.0, 210.0, 190.0, 89.0]\n",
      "User  9.0  :  [487.0, 479.0, 527.0, 521.0, 691.0, 298.0, 507.0, 340.0, 6.0, 286.0]\n",
      "User  10.0  :  [483.0, 474.0, 127.0, 98.0, 603.0, 488.0, 493.0, 56.0, 100.0, 199.0]\n",
      "User  11.0  :  [190.0, 100.0, 735.0, 12.0, 524.0, 191.0, 194.0, 22.0, 736.0, 740.0]\n",
      "User  12.0  :  [318.0, 50.0, 196.0, 172.0, 96.0, 28.0, 191.0, 735.0, 204.0, 82.0]\n",
      "User  13.0  :  [868.0, 318.0, 480.0, 483.0, 694.0, 524.0, 787.0, 64.0, 601.0, 181.0]\n",
      "User  14.0  :  [174.0, 474.0, 408.0, 922.0, 357.0, 50.0, 603.0, 519.0, 98.0, 498.0]\n",
      "User  15.0  :  [127.0, 889.0, 1.0, 459.0, 7.0, 286.0, 137.0, 274.0, 924.0, 9.0]\n"
     ]
    }
   ],
   "source": [
    "top10 = get_top_n(test_df)\n",
    "for user in top10.keys():\n",
    "    if user < 16:\n",
    "        print(\"User \", user, \" : \", top10[user])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac5166",
   "metadata": {},
   "source": [
    "### Item based KNN recommender system model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c221822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "sim_options_items = {'name': 'pearson_baseline', 'user_based': False}\n",
    "\n",
    "itemBasedKNN = KNNBaseline(sim_options=sim_options_items)\n",
    "itemBasedKNN.fit(trainset)\n",
    "\n",
    "item_test_df = test_df.copy()\n",
    "prediction = []\n",
    "\n",
    "for index, row in item_test_df.iterrows():\n",
    "    pred = itemBasedKNN.predict(row[\"user_id\"], row[\"item_id\"], row[\"rating\"], verbose=False)\n",
    "    prediction.append(pred[3])\n",
    "    \n",
    "item_test_df['predictions'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "965a7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User  1.0  :  [170.0, 174.0, 272.0, 64.0, 134.0, 100.0, 12.0, 60.0, 190.0, 98.0]\n",
      "User  2.0  :  [50.0, 315.0, 251.0, 19.0, 313.0, 297.0, 316.0, 303.0, 292.0, 298.0]\n",
      "User  3.0  :  [318.0, 345.0, 272.0, 307.0, 331.0, 354.0, 348.0, 335.0, 327.0, 334.0]\n",
      "User  4.0  :  [303.0, 357.0, 361.0, 50.0, 354.0, 288.0, 356.0, 260.0, 264.0, 294.0]\n",
      "User  5.0  :  [89.0, 176.0, 173.0, 100.0, 144.0, 1.0, 79.0, 69.0, 109.0, 429.0]\n",
      "User  6.0  :  [483.0, 515.0, 318.0, 513.0, 488.0, 357.0, 134.0, 480.0, 478.0, 199.0]\n",
      "User  7.0  :  [643.0, 483.0, 174.0, 172.0, 223.0, 657.0, 528.0, 8.0, 127.0, 191.0]\n",
      "User  8.0  :  [50.0, 511.0, 183.0, 172.0, 79.0, 176.0, 127.0, 651.0, 89.0, 190.0]\n",
      "User  9.0  :  [479.0, 527.0, 487.0, 521.0, 340.0, 298.0, 507.0, 6.0, 691.0, 286.0]\n",
      "User  10.0  :  [483.0, 603.0, 98.0, 474.0, 64.0, 127.0, 191.0, 488.0, 199.0, 651.0]\n",
      "User  11.0  :  [190.0, 735.0, 191.0, 216.0, 12.0, 22.0, 100.0, 194.0, 429.0, 736.0]\n",
      "User  12.0  :  [50.0, 196.0, 318.0, 735.0, 28.0, 282.0, 172.0, 143.0, 96.0, 15.0]\n",
      "User  13.0  :  [480.0, 483.0, 185.0, 519.0, 180.0, 524.0, 530.0, 488.0, 178.0, 651.0]\n",
      "User  14.0  :  [603.0, 519.0, 474.0, 498.0, 357.0, 98.0, 408.0, 313.0, 50.0, 174.0]\n",
      "User  15.0  :  [127.0, 286.0, 459.0, 1.0, 7.0, 889.0, 864.0, 222.0, 20.0, 148.0]\n"
     ]
    }
   ],
   "source": [
    "top10 = get_top_n(item_test_df)\n",
    "for user in top10.keys():\n",
    "    if user < 16:\n",
    "        print(\"User \", user, \" : \", top10[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886165d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
