{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcd0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from numba import jit\n",
    "from scipy import sparse, special\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4fd018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonMF(BaseEstimator, TransformerMixin):\n",
    "    ''' Poisson matrix factorization with batch inference '''\n",
    "    def __init__(self, n_components=100, max_iter=100, tol=0.0001,\n",
    "                 smoothness=100, random_state=None, verbose=False,\n",
    "                 **kwargs):\n",
    "        ''' Poisson matrix factorization\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        n_components : int\n",
    "            Number of latent components\n",
    "\n",
    "        max_iter : int\n",
    "            Maximal number of iterations to perform\n",
    "\n",
    "        tol : float\n",
    "            The threshold on the increase of the objective to stop the\n",
    "            iteration\n",
    "\n",
    "        smoothness : int\n",
    "            Smoothness on the initialization variational parameters\n",
    "\n",
    "        random_state : int or RandomState\n",
    "            Pseudo random number generator used for sampling\n",
    "\n",
    "        verbose : bool\n",
    "            Whether to show progress during model fitting\n",
    "\n",
    "        **kwargs: dict\n",
    "            Model hyperparameters\n",
    "        '''\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.smoothness = smoothness\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if type(self.random_state) is int:\n",
    "            np.random.seed(self.random_state)\n",
    "        elif self.random_state is not None:\n",
    "            np.random.setstate(self.random_state)\n",
    "\n",
    "        self._parse_args(**kwargs)\n",
    "\n",
    "    def _parse_args(self, **kwargs):\n",
    "        self.a = float(kwargs.get('a', 0.1))\n",
    "        self.b = float(kwargs.get('b', 0.1))\n",
    "        self.c = float(kwargs.get('c', 0.1))\n",
    "        self.d = float(kwargs.get('d', 0.1))\n",
    "\n",
    "    def _init_users(self, n_users):\n",
    "        # variational parameters for theta\n",
    "        self.gamma_t = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(self.n_components, n_users)\n",
    "                            ).astype(np.float32)\n",
    "        self.rho_t = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(self.n_components, n_users)\n",
    "                            ).astype(np.float32)\n",
    "        self.Et, self.Elogt = _compute_expectations(self.gamma_t, self.rho_t)\n",
    "\n",
    "    def _init_items(self, n_items):\n",
    "        # variational parameters for beta\n",
    "        self.gamma_b = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(n_items, self.n_components)\n",
    "                            ).astype(np.float32)\n",
    "        self.rho_b = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(n_items, self.n_components)\n",
    "                            ).astype(np.float32)\n",
    "        self.Eb, self.Elogb = _compute_expectations(self.gamma_b, self.rho_b)\n",
    "\n",
    "    def fit(self, X, rows, cols, vad=None):\n",
    "        '''Fit the model to the data in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_feats)\n",
    "            Training data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: object\n",
    "            Returns the instance itself.\n",
    "        '''\n",
    "        n_items, n_users = X.shape\n",
    "        self._init_items(n_items)\n",
    "        self._init_users(n_users)\n",
    "        self._update(X, rows, cols, vad=vad)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, rows, cols, attr=None):\n",
    "        '''Encode the data as a linear combination of the latent components.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_feats)\n",
    "\n",
    "        attr: string\n",
    "            The name of attribute, default 'Eb'. Can be changed to Elogb to\n",
    "            obtain E_q[log beta] as transformed data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : array-like, shape(n_samples, n_filters)\n",
    "            Transformed data, as specified by attr.\n",
    "        '''\n",
    "\n",
    "        if not hasattr(self, 'Et'):\n",
    "            raise ValueError('There are no pre-trained components.')\n",
    "        n_items, n_users = X.shape\n",
    "        if n_users != self.Et.shape[1]:\n",
    "            raise ValueError('The dimension of the transformed data '\n",
    "                             'does not match with the existing components.')\n",
    "        if attr is None:\n",
    "            attr = 'Eb'\n",
    "        self._init_items(n_items)\n",
    "        self._update(X, rows, cols, update_theta=False)\n",
    "        return getattr(self, attr)\n",
    "\n",
    "    def _update(self, X, rows, cols, update_theta=True, vad=None):\n",
    "        # alternating between update latent components and weights\n",
    "        old_pll = -np.inf\n",
    "        for i in range(self.max_iter):\n",
    "            if update_theta:\n",
    "                self._update_users(X, rows, cols)\n",
    "            self._update_items(X, rows, cols)\n",
    "            if vad is not None:\n",
    "                pred_ll = self.pred_loglikeli(**vad)\n",
    "                improvement = (pred_ll - old_pll) / abs(old_pll)\n",
    "                if self.verbose:\n",
    "                    print('ITERATION: %d\\tPred_ll: %.2f\\tOld Pred_ll: %.2f\\t'\n",
    "                        'Improvement: %.5f' % (i, pred_ll, old_pll, improvement))\n",
    "                    sys.stdout.flush()\n",
    "                if improvement < self.tol:\n",
    "                    break\n",
    "                old_pll = pred_ll\n",
    "        pass\n",
    "\n",
    "    def _update_users(self, X, rows, cols):\n",
    "        ratioT = sparse.csr_matrix((X.data / self._xexplog(rows, cols),\n",
    "                                    (rows, cols)),\n",
    "                                   dtype=np.float32, shape=X.shape).transpose()\n",
    "        self.gamma_t = self.a + np.exp(self.Elogt) * \\\n",
    "            ratioT.dot(np.exp(self.Elogb)).T\n",
    "        self.rho_t = self.b + np.sum(self.Eb, axis=0, keepdims=True).T\n",
    "        self.Et, self.Elogt = _compute_expectations(self.gamma_t, self.rho_t)\n",
    "\n",
    "    def _update_items(self, X, rows, cols):\n",
    "        ratio = sparse.csr_matrix((X.data / self._xexplog(rows, cols),\n",
    "                                   (rows, cols)),\n",
    "                                  dtype=np.float32, shape=X.shape)\n",
    "        self.gamma_b = self.c + np.exp(self.Elogb) * \\\n",
    "            ratio.dot(np.exp(self.Elogt.T))\n",
    "        self.rho_b = self.d + np.sum(self.Et, axis=1)\n",
    "        self.Eb, self.Elogb = _compute_expectations(self.gamma_b, self.rho_b)\n",
    "\n",
    "    def _xexplog(self, rows, cols):\n",
    "        '''\n",
    "        sum_k exp(E[log theta_{ik} * beta_{kd}])\n",
    "        '''\n",
    "        data = _inner(np.exp(self.Elogb), np.exp(self.Elogt), rows, cols)\n",
    "        return data\n",
    "\n",
    "    def pred_loglikeli(self, X_new, rows_new, cols_new):\n",
    "        X_pred = _inner(self.Eb, self.Et, rows_new, cols_new)\n",
    "        pred_ll = np.mean(X_new * np.log(X_pred) - X_pred)\n",
    "        return pred_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac13e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inner(beta, theta, rows, cols):\n",
    "    n_ratings = rows.size\n",
    "    n_components, n_users = theta.shape\n",
    "    beta = beta.reshape((-1, n_components))    \n",
    "    data = np.empty(n_ratings, dtype=np.float32)\n",
    "    for i in range(n_ratings):\n",
    "        data[i] = 0\n",
    "        for j in range(n_components):\n",
    "            beta_ij = beta[rows[i], j]\n",
    "            theta_ij = theta[j, cols[i]]\n",
    "#             data[i] += beta[rows[i] * n_components + j] * theta[j * n_users + cols[i]]\n",
    "            data[i] += beta_ij*theta_ij\n",
    "    return data\n",
    "\n",
    "def _compute_expectations(alpha, beta):\n",
    "    '''\n",
    "    Given x ~ Gam(alpha, beta), compute E[x] and E[log x]\n",
    "    '''\n",
    "    return (alpha / beta, special.psi(alpha) - np.log(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf5fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "trainDf = pd.read_csv('C:/Users/kenny/Desktop/Spring 2021/CSE547_Project/data/MovieLens.training', sep='\\t', lineterminator='\\n')\n",
    "trainDf.columns = train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05541c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf=trainDf.drop([\"timestamp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377463d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "n_users = 943\n",
    "n_movies = 1682\n",
    "trainDf[\"user_id\"] -= 1\n",
    "trainDf[\"item_id\"] -= 1\n",
    "def load_data(df, colnames=[\"uid\", \"sid\", \"rating\"], shape=(n_users, n_movies)):\n",
    "    user, item, rating = colnames[0], colnames[1], colnames[2]\n",
    "    rows, cols, vals = np.array(df[user]), np.array(df[item]), np.array(df[rating])\n",
    "    data = sparse.csr_matrix((vals, (rows, cols)), dtype=np.float32, shape=shape)\n",
    "    return data\n",
    "def exp_to_imp(data, cutoff=1e-10):\n",
    "    data_imp = data.copy()\n",
    "    data_imp.data[data_imp.data < cutoff] = 0\n",
    "    data_imp.data[data_imp.data >= cutoff] = 1\n",
    "    data_imp.data = data_imp.data.astype('int32')\n",
    "    data_imp.eliminate_zeros()\n",
    "    return data_imp\n",
    "data = load_data(trainDf, colnames=['user_id', 'item_id', 'rating'], shape=(n_users, n_movies))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be175aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 10)\n",
      "(1682, 10)\n"
     ]
    }
   ],
   "source": [
    "data_imp = exp_to_imp(data, 0.5)\n",
    "data_coo = data_imp.tocoo()\n",
    "row_tr, col_tr = data_coo.row, data_coo.col\n",
    "pf = PoissonMF(n_components=10, max_iter=100)\n",
    "pf.fit(data, row_tr, col_tr)\n",
    "pi, lamb = pf.Eb.copy(), pf.Et.T\n",
    "\n",
    "print(pi.shape)\n",
    "print(lamb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be4d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat=np.matmul(pi,lamb.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b884b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d38deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e8e3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79969</th>\n",
       "      <td>942</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79970</th>\n",
       "      <td>942</td>\n",
       "      <td>720</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79971</th>\n",
       "      <td>942</td>\n",
       "      <td>721</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79972</th>\n",
       "      <td>942</td>\n",
       "      <td>723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79973</th>\n",
       "      <td>942</td>\n",
       "      <td>731</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79974</th>\n",
       "      <td>942</td>\n",
       "      <td>738</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79975</th>\n",
       "      <td>942</td>\n",
       "      <td>755</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79976</th>\n",
       "      <td>942</td>\n",
       "      <td>762</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79977</th>\n",
       "      <td>942</td>\n",
       "      <td>764</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79978</th>\n",
       "      <td>942</td>\n",
       "      <td>784</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79979</th>\n",
       "      <td>942</td>\n",
       "      <td>793</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79980</th>\n",
       "      <td>942</td>\n",
       "      <td>795</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79981</th>\n",
       "      <td>942</td>\n",
       "      <td>807</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79982</th>\n",
       "      <td>942</td>\n",
       "      <td>815</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79983</th>\n",
       "      <td>942</td>\n",
       "      <td>823</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79984</th>\n",
       "      <td>942</td>\n",
       "      <td>824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79985</th>\n",
       "      <td>942</td>\n",
       "      <td>830</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79986</th>\n",
       "      <td>942</td>\n",
       "      <td>839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79987</th>\n",
       "      <td>942</td>\n",
       "      <td>927</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79988</th>\n",
       "      <td>942</td>\n",
       "      <td>940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79989</th>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79990</th>\n",
       "      <td>942</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79991</th>\n",
       "      <td>942</td>\n",
       "      <td>1027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79992</th>\n",
       "      <td>942</td>\n",
       "      <td>1043</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79993</th>\n",
       "      <td>942</td>\n",
       "      <td>1046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>942</td>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>942</td>\n",
       "      <td>1073</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>942</td>\n",
       "      <td>1187</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>942</td>\n",
       "      <td>1227</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>942</td>\n",
       "      <td>1329</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79999 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "0            0        1       3\n",
       "1            0        2       4\n",
       "2            0        3       3\n",
       "3            0        4       3\n",
       "4            0        6       4\n",
       "5            0        7       1\n",
       "6            0        8       5\n",
       "7            0       10       2\n",
       "8            0       12       5\n",
       "9            0       14       5\n",
       "10           0       15       5\n",
       "11           0       17       4\n",
       "12           0       18       5\n",
       "13           0       20       1\n",
       "14           0       21       4\n",
       "15           0       24       4\n",
       "16           0       25       3\n",
       "17           0       27       4\n",
       "18           0       28       1\n",
       "19           0       29       3\n",
       "20           0       31       5\n",
       "21           0       33       2\n",
       "22           0       34       1\n",
       "23           0       36       2\n",
       "24           0       37       3\n",
       "25           0       39       3\n",
       "26           0       40       2\n",
       "27           0       41       5\n",
       "28           0       42       4\n",
       "29           0       44       5\n",
       "...        ...      ...     ...\n",
       "79969      942      719       1\n",
       "79970      942      720       5\n",
       "79971      942      721       3\n",
       "79972      942      723       1\n",
       "79973      942      731       4\n",
       "79974      942      738       4\n",
       "79975      942      755       2\n",
       "79976      942      762       4\n",
       "79977      942      764       3\n",
       "79978      942      784       2\n",
       "79979      942      793       3\n",
       "79980      942      795       3\n",
       "79981      942      807       4\n",
       "79982      942      815       4\n",
       "79983      942      823       4\n",
       "79984      942      824       3\n",
       "79985      942      830       2\n",
       "79986      942      839       4\n",
       "79987      942      927       5\n",
       "79988      942      940       1\n",
       "79989      942      942       5\n",
       "79990      942     1010       2\n",
       "79991      942     1027       2\n",
       "79992      942     1043       3\n",
       "79993      942     1046       2\n",
       "79994      942     1066       2\n",
       "79995      942     1073       4\n",
       "79996      942     1187       3\n",
       "79997      942     1227       3\n",
       "79998      942     1329       3\n",
       "\n",
       "[79999 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fbb5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=np.zeros((943,1682))\n",
    "for i in range(len(trainDf)):\n",
    "    R[trainDf['user_id'][i]][trainDf['item_id'][i]]=trainDf['rating'][i]\n",
    "I=(R>0)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc9173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(U,V,R,I,ahat,gamma,lamb):\n",
    "    s=0\n",
    "    k=0\n",
    "    m=0\n",
    "    for i in range(len(U)):\n",
    "        for j in range(len(V)):\n",
    "            s=s+I[i][j]*(R[i][j]-np.dot(U[i],V[j])-ahat[i][j]*gamma[i])**2\n",
    "    for i in range(len(U)):\n",
    "        k=k+LA.norm(U[i])**2\n",
    "    for i in range(len(V)):\n",
    "        m=m+LA.norm(V[i])**2\n",
    "    return s+lamb*(m+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "62175959",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=[]\n",
    "num_latent_factors=10\n",
    "V=csr_matrix((1682, num_latent_factors))\n",
    "lamb=0.001\n",
    "U=csr_matrix(np.zeros((943,num_latent_factors))+0.5)\n",
    "gamma=np.zeros(943)+0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7cda8a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.append(calculate_loss(U.toarray(),V.toarray(),R,I,a_hat,gamma,lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "21b7fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for j in range (10):\n",
    "    #UU=np.matmul(U.toarray().T,U.toarray())\n",
    "    for i in range(1682):\n",
    "        U_i = U.toarray()[R[:, i] > 0,:]\n",
    "        A=csr_matrix(np.matmul(U_i.T,U_i)+lamb*np.identity(num_latent_factors))\n",
    "        B=csr_matrix(np.matmul(U_i.T,R[ R[:,i] > 0,i])-np.matmul(U_i.T,np.multiply(gamma[ R[:,i] > 0],a_hat[ R[:,i] > 0,i])))\n",
    "        V[i,:] = spsolve(A, csr_matrix.transpose(B))\n",
    "    #V = V[:, R[i, :] > 0]\n",
    "    #VV=np.matmul(V.toarray().T,V.toarray())\n",
    "    for u in range(943):\n",
    "        V_u = V.toarray()[R[u, :] > 0,:]\n",
    "        A=csr_matrix(np.matmul(V_u.T,V_u)+lamb*np.identity(num_latent_factors))\n",
    "        B=csr_matrix(np.matmul(V_u.T,R[u, R[u, :] > 0])-gamma[u]*np.matmul(V_u.T,a_hat[u, R[u, :] > 0]))\n",
    "        #B=csr_matrix(np.matmul(np.matmul(Y.toarray().T,(L_C_u_1[u]+np.identity(3000))),L_P_2[u]))\n",
    "        U[u,:] = spsolve(A, csr_matrix.transpose(B))\n",
    "        gamma[u]=(np.dot(R[u, R[u, :] > 0],a_hat[u, R[u, :] > 0])-np.dot(np.matmul(U.toarray()[u],V_u.T),a_hat[u, R[u, :] > 0]))/np.dot(a_hat[u, R[u, :] > 0],a_hat[u, R[u, :] > 0])\n",
    "    loss.append(calculate_loss(U.toarray(),V.toarray(),R,I,a_hat,gamma,lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bb34e85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(1,len(loss)+1,1),loss)\n",
    "plt.title('Cost function vs iterations')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ea18790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[875624.530067225,\n",
       " 65905.70677354326,\n",
       " 56526.02796438471,\n",
       " 43227.602260326195,\n",
       " 40911.68344354152,\n",
       " 39662.11113018942,\n",
       " 38821.67533249252,\n",
       " 38191.02295806778,\n",
       " 37686.137807590334,\n",
       " 37266.82283640529,\n",
       " 36913.743939886284]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "015c8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_hat=np.zeros(a_hat.shape)\n",
    "for i in range(len(gamma)):\n",
    "    R_hat[i,:]=gamma[i]*a_hat[i]\n",
    "R_hat=np.multiply(R_hat,I)+np.matmul(U.toarray()[0],V.toarray().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a857e98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.14639636,  3.0692047 ,  4.02236219, ...,  0.52961875,\n",
       "        -0.57531311,  0.10481288],\n",
       "       [ 3.13106562,  2.91624077,  3.90788506, ...,  0.52961875,\n",
       "        -0.57531311,  0.10481288],\n",
       "       [ 3.14639636,  2.91624077,  3.90788506, ...,  0.52961875,\n",
       "        -0.57531311,  0.10481288],\n",
       "       ...,\n",
       "       [ 4.21170457,  2.91624077,  3.90788506, ...,  0.52961875,\n",
       "        -0.57531311,  0.10481288],\n",
       "       [ 3.14639636,  2.91624077,  3.90788506, ...,  0.52961875,\n",
       "        -0.57531311,  0.10481288],\n",
       "       [ 3.14639636,  2.99606641,  3.90788506, ...,  0.52961875,\n",
       "        -0.57531311,  0.10481288]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4bbde5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc043bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79969</th>\n",
       "      <td>942</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79970</th>\n",
       "      <td>942</td>\n",
       "      <td>720</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79971</th>\n",
       "      <td>942</td>\n",
       "      <td>721</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79972</th>\n",
       "      <td>942</td>\n",
       "      <td>723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79973</th>\n",
       "      <td>942</td>\n",
       "      <td>731</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79974</th>\n",
       "      <td>942</td>\n",
       "      <td>738</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79975</th>\n",
       "      <td>942</td>\n",
       "      <td>755</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79976</th>\n",
       "      <td>942</td>\n",
       "      <td>762</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79977</th>\n",
       "      <td>942</td>\n",
       "      <td>764</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79978</th>\n",
       "      <td>942</td>\n",
       "      <td>784</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79979</th>\n",
       "      <td>942</td>\n",
       "      <td>793</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79980</th>\n",
       "      <td>942</td>\n",
       "      <td>795</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79981</th>\n",
       "      <td>942</td>\n",
       "      <td>807</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79982</th>\n",
       "      <td>942</td>\n",
       "      <td>815</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79983</th>\n",
       "      <td>942</td>\n",
       "      <td>823</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79984</th>\n",
       "      <td>942</td>\n",
       "      <td>824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79985</th>\n",
       "      <td>942</td>\n",
       "      <td>830</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79986</th>\n",
       "      <td>942</td>\n",
       "      <td>839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79987</th>\n",
       "      <td>942</td>\n",
       "      <td>927</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79988</th>\n",
       "      <td>942</td>\n",
       "      <td>940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79989</th>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79990</th>\n",
       "      <td>942</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79991</th>\n",
       "      <td>942</td>\n",
       "      <td>1027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79992</th>\n",
       "      <td>942</td>\n",
       "      <td>1043</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79993</th>\n",
       "      <td>942</td>\n",
       "      <td>1046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>942</td>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>942</td>\n",
       "      <td>1073</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>942</td>\n",
       "      <td>1187</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>942</td>\n",
       "      <td>1227</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>942</td>\n",
       "      <td>1329</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79909 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "90           0      171       5\n",
       "91           0      172       5\n",
       "92           0      175       5\n",
       "93           0      177       5\n",
       "94           0      178       3\n",
       "95           0      180       5\n",
       "96           0      181       4\n",
       "97           0      186       4\n",
       "98           0      190       5\n",
       "99           0      191       4\n",
       "100          0      193       4\n",
       "101          0      194       5\n",
       "102          0      196       5\n",
       "103          0      197       5\n",
       "104          0      198       4\n",
       "105          0      202       4\n",
       "106          0      203       5\n",
       "107          0      204       3\n",
       "108          0      206       5\n",
       "109          0      210       3\n",
       "110          0      215       5\n",
       "111          0      216       3\n",
       "112          0      219       3\n",
       "113          0      222       5\n",
       "114          0      230       1\n",
       "115          0      233       4\n",
       "116          0      236       2\n",
       "117          0      237       4\n",
       "118          0      238       4\n",
       "119          0      239       3\n",
       "...        ...      ...     ...\n",
       "79969      942      719       1\n",
       "79970      942      720       5\n",
       "79971      942      721       3\n",
       "79972      942      723       1\n",
       "79973      942      731       4\n",
       "79974      942      738       4\n",
       "79975      942      755       2\n",
       "79976      942      762       4\n",
       "79977      942      764       3\n",
       "79978      942      784       2\n",
       "79979      942      793       3\n",
       "79980      942      795       3\n",
       "79981      942      807       4\n",
       "79982      942      815       4\n",
       "79983      942      823       4\n",
       "79984      942      824       3\n",
       "79985      942      830       2\n",
       "79986      942      839       4\n",
       "79987      942      927       5\n",
       "79988      942      940       1\n",
       "79989      942      942       5\n",
       "79990      942     1010       2\n",
       "79991      942     1027       2\n",
       "79992      942     1043       3\n",
       "79993      942     1046       2\n",
       "79994      942     1066       2\n",
       "79995      942     1073       4\n",
       "79996      942     1187       3\n",
       "79997      942     1227       3\n",
       "79998      942     1329       3\n",
       "\n",
       "[79909 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf[90:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
