{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcd0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from numba import jit\n",
    "from scipy import sparse, special\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4fd018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonMF(BaseEstimator, TransformerMixin):\n",
    "    ''' Poisson matrix factorization with batch inference '''\n",
    "    def __init__(self, n_components=100, max_iter=100, tol=0.0001,\n",
    "                 smoothness=100, random_state=None, verbose=False,\n",
    "                 **kwargs):\n",
    "        ''' Poisson matrix factorization\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        n_components : int\n",
    "            Number of latent components\n",
    "\n",
    "        max_iter : int\n",
    "            Maximal number of iterations to perform\n",
    "\n",
    "        tol : float\n",
    "            The threshold on the increase of the objective to stop the\n",
    "            iteration\n",
    "\n",
    "        smoothness : int\n",
    "            Smoothness on the initialization variational parameters\n",
    "\n",
    "        random_state : int or RandomState\n",
    "            Pseudo random number generator used for sampling\n",
    "\n",
    "        verbose : bool\n",
    "            Whether to show progress during model fitting\n",
    "\n",
    "        **kwargs: dict\n",
    "            Model hyperparameters\n",
    "        '''\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.smoothness = smoothness\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if type(self.random_state) is int:\n",
    "            np.random.seed(self.random_state)\n",
    "        elif self.random_state is not None:\n",
    "            np.random.setstate(self.random_state)\n",
    "\n",
    "        self._parse_args(**kwargs)\n",
    "\n",
    "    def _parse_args(self, **kwargs):\n",
    "        self.a = float(kwargs.get('a', 0.1))\n",
    "        self.b = float(kwargs.get('b', 0.1))\n",
    "        self.c = float(kwargs.get('c', 0.1))\n",
    "        self.d = float(kwargs.get('d', 0.1))\n",
    "\n",
    "    def _init_users(self, n_users):\n",
    "        # variational parameters for theta\n",
    "        self.gamma_t = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(self.n_components, n_users)\n",
    "                            ).astype(np.float32)\n",
    "        self.rho_t = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(self.n_components, n_users)\n",
    "                            ).astype(np.float32)\n",
    "        self.Et, self.Elogt = _compute_expectations(self.gamma_t, self.rho_t)\n",
    "\n",
    "    def _init_items(self, n_items):\n",
    "        # variational parameters for beta\n",
    "        self.gamma_b = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(n_items, self.n_components)\n",
    "                            ).astype(np.float32)\n",
    "        self.rho_b = self.smoothness * \\\n",
    "            np.random.gamma(self.smoothness, 1. / self.smoothness,\n",
    "                            size=(n_items, self.n_components)\n",
    "                            ).astype(np.float32)\n",
    "        self.Eb, self.Elogb = _compute_expectations(self.gamma_b, self.rho_b)\n",
    "\n",
    "    def fit(self, X, rows, cols, vad=None):\n",
    "        '''Fit the model to the data in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_feats)\n",
    "            Training data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: object\n",
    "            Returns the instance itself.\n",
    "        '''\n",
    "        n_items, n_users = X.shape\n",
    "        self._init_items(n_items)\n",
    "        self._init_users(n_users)\n",
    "        self._update(X, rows, cols, vad=vad)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, rows, cols, attr=None):\n",
    "        '''Encode the data as a linear combination of the latent components.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_feats)\n",
    "\n",
    "        attr: string\n",
    "            The name of attribute, default 'Eb'. Can be changed to Elogb to\n",
    "            obtain E_q[log beta] as transformed data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : array-like, shape(n_samples, n_filters)\n",
    "            Transformed data, as specified by attr.\n",
    "        '''\n",
    "\n",
    "        if not hasattr(self, 'Et'):\n",
    "            raise ValueError('There are no pre-trained components.')\n",
    "        n_items, n_users = X.shape\n",
    "        if n_users != self.Et.shape[1]:\n",
    "            raise ValueError('The dimension of the transformed data '\n",
    "                             'does not match with the existing components.')\n",
    "        if attr is None:\n",
    "            attr = 'Eb'\n",
    "        self._init_items(n_items)\n",
    "        self._update(X, rows, cols, update_theta=False)\n",
    "        return getattr(self, attr)\n",
    "\n",
    "    def _update(self, X, rows, cols, update_theta=True, vad=None):\n",
    "        # alternating between update latent components and weights\n",
    "        old_pll = -np.inf\n",
    "        for i in range(self.max_iter):\n",
    "            if update_theta:\n",
    "                self._update_users(X, rows, cols)\n",
    "            self._update_items(X, rows, cols)\n",
    "            if vad is not None:\n",
    "                pred_ll = self.pred_loglikeli(**vad)\n",
    "                improvement = (pred_ll - old_pll) / abs(old_pll)\n",
    "                if self.verbose:\n",
    "                    print('ITERATION: %d\\tPred_ll: %.2f\\tOld Pred_ll: %.2f\\t'\n",
    "                        'Improvement: %.5f' % (i, pred_ll, old_pll, improvement))\n",
    "                    sys.stdout.flush()\n",
    "                if improvement < self.tol:\n",
    "                    break\n",
    "                old_pll = pred_ll\n",
    "        pass\n",
    "\n",
    "    def _update_users(self, X, rows, cols):\n",
    "        ratioT = sparse.csr_matrix((X.data / self._xexplog(rows, cols),\n",
    "                                    (rows, cols)),\n",
    "                                   dtype=np.float32, shape=X.shape).transpose()\n",
    "        self.gamma_t = self.a + np.exp(self.Elogt) * \\\n",
    "            ratioT.dot(np.exp(self.Elogb)).T\n",
    "        self.rho_t = self.b + np.sum(self.Eb, axis=0, keepdims=True).T\n",
    "        self.Et, self.Elogt = _compute_expectations(self.gamma_t, self.rho_t)\n",
    "\n",
    "    def _update_items(self, X, rows, cols):\n",
    "        ratio = sparse.csr_matrix((X.data / self._xexplog(rows, cols),\n",
    "                                   (rows, cols)),\n",
    "                                  dtype=np.float32, shape=X.shape)\n",
    "        self.gamma_b = self.c + np.exp(self.Elogb) * \\\n",
    "            ratio.dot(np.exp(self.Elogt.T))\n",
    "        self.rho_b = self.d + np.sum(self.Et, axis=1)\n",
    "        self.Eb, self.Elogb = _compute_expectations(self.gamma_b, self.rho_b)\n",
    "\n",
    "    def _xexplog(self, rows, cols):\n",
    "        '''\n",
    "        sum_k exp(E[log theta_{ik} * beta_{kd}])\n",
    "        '''\n",
    "        data = _inner(np.exp(self.Elogb), np.exp(self.Elogt), rows, cols)\n",
    "        return data\n",
    "\n",
    "    def pred_loglikeli(self, X_new, rows_new, cols_new):\n",
    "        X_pred = _inner(self.Eb, self.Et, rows_new, cols_new)\n",
    "        pred_ll = np.mean(X_new * np.log(X_pred) - X_pred)\n",
    "        return pred_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac13e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inner(beta, theta, rows, cols):\n",
    "    n_ratings = rows.size\n",
    "    n_components, n_users = theta.shape\n",
    "    beta = beta.reshape((-1, n_components))    \n",
    "    data = np.empty(n_ratings, dtype=np.float32)\n",
    "    for i in range(n_ratings):\n",
    "        data[i] = 0\n",
    "        for j in range(n_components):\n",
    "            beta_ij = beta[rows[i], j]\n",
    "            theta_ij = theta[j, cols[i]]\n",
    "#             data[i] += beta[rows[i] * n_components + j] * theta[j * n_users + cols[i]]\n",
    "            data[i] += beta_ij*theta_ij\n",
    "    return data\n",
    "\n",
    "def _compute_expectations(alpha, beta):\n",
    "    '''\n",
    "    Given x ~ Gam(alpha, beta), compute E[x] and E[log x]\n",
    "    '''\n",
    "    return (alpha / beta, special.psi(alpha) - np.log(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf5fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "trainDf = pd.read_csv('C:/Users/kenny/Desktop/Spring 2021/CSE547_Project/data/MovieLens.training', sep='\\t', lineterminator='\\n')\n",
    "trainDf.columns = train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05541c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf=trainDf.drop([\"timestamp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377463d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "n_users = 943\n",
    "n_movies = 1682\n",
    "trainDf[\"user_id\"] -= 1\n",
    "trainDf[\"item_id\"] -= 1\n",
    "def load_data(df, colnames=[\"uid\", \"sid\", \"rating\"], shape=(n_users, n_movies)):\n",
    "    user, item, rating = colnames[0], colnames[1], colnames[2]\n",
    "    rows, cols, vals = np.array(df[user]), np.array(df[item]), np.array(df[rating])\n",
    "    data = sparse.csr_matrix((vals, (rows, cols)), dtype=np.float32, shape=shape)\n",
    "    return data\n",
    "def exp_to_imp(data, cutoff=1e-10):\n",
    "    data_imp = data.copy()\n",
    "    data_imp.data[data_imp.data < cutoff] = 0\n",
    "    data_imp.data[data_imp.data >= cutoff] = 1\n",
    "    data_imp.data = data_imp.data.astype('int32')\n",
    "    data_imp.eliminate_zeros()\n",
    "    return data_imp\n",
    "data = load_data(trainDf, colnames=['user_id', 'item_id', 'rating'], shape=(n_users, n_movies))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be175aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 10)\n",
      "(1682, 10)\n"
     ]
    }
   ],
   "source": [
    "data_imp = exp_to_imp(data, 0.5)\n",
    "data_coo = data_imp.tocoo()\n",
    "row_tr, col_tr = data_coo.row, data_coo.col\n",
    "pf = PoissonMF(n_components=10, max_iter=100)\n",
    "pf.fit(data, row_tr, col_tr)\n",
    "pi, lamb = pf.Eb.copy(), pf.Et.T\n",
    "\n",
    "print(pi.shape)\n",
    "print(lamb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be4d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat=np.matmul(pi,lamb.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b884b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d38deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e8e3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79969</th>\n",
       "      <td>942</td>\n",
       "      <td>719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79970</th>\n",
       "      <td>942</td>\n",
       "      <td>720</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79971</th>\n",
       "      <td>942</td>\n",
       "      <td>721</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79972</th>\n",
       "      <td>942</td>\n",
       "      <td>723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79973</th>\n",
       "      <td>942</td>\n",
       "      <td>731</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79974</th>\n",
       "      <td>942</td>\n",
       "      <td>738</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79975</th>\n",
       "      <td>942</td>\n",
       "      <td>755</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79976</th>\n",
       "      <td>942</td>\n",
       "      <td>762</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79977</th>\n",
       "      <td>942</td>\n",
       "      <td>764</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79978</th>\n",
       "      <td>942</td>\n",
       "      <td>784</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79979</th>\n",
       "      <td>942</td>\n",
       "      <td>793</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79980</th>\n",
       "      <td>942</td>\n",
       "      <td>795</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79981</th>\n",
       "      <td>942</td>\n",
       "      <td>807</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79982</th>\n",
       "      <td>942</td>\n",
       "      <td>815</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79983</th>\n",
       "      <td>942</td>\n",
       "      <td>823</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79984</th>\n",
       "      <td>942</td>\n",
       "      <td>824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79985</th>\n",
       "      <td>942</td>\n",
       "      <td>830</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79986</th>\n",
       "      <td>942</td>\n",
       "      <td>839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79987</th>\n",
       "      <td>942</td>\n",
       "      <td>927</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79988</th>\n",
       "      <td>942</td>\n",
       "      <td>940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79989</th>\n",
       "      <td>942</td>\n",
       "      <td>942</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79990</th>\n",
       "      <td>942</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79991</th>\n",
       "      <td>942</td>\n",
       "      <td>1027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79992</th>\n",
       "      <td>942</td>\n",
       "      <td>1043</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79993</th>\n",
       "      <td>942</td>\n",
       "      <td>1046</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>942</td>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>942</td>\n",
       "      <td>1073</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>942</td>\n",
       "      <td>1187</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>942</td>\n",
       "      <td>1227</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>942</td>\n",
       "      <td>1329</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79999 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating\n",
       "0            0        1       3\n",
       "1            0        2       4\n",
       "2            0        3       3\n",
       "3            0        4       3\n",
       "4            0        6       4\n",
       "5            0        7       1\n",
       "6            0        8       5\n",
       "7            0       10       2\n",
       "8            0       12       5\n",
       "9            0       14       5\n",
       "10           0       15       5\n",
       "11           0       17       4\n",
       "12           0       18       5\n",
       "13           0       20       1\n",
       "14           0       21       4\n",
       "15           0       24       4\n",
       "16           0       25       3\n",
       "17           0       27       4\n",
       "18           0       28       1\n",
       "19           0       29       3\n",
       "20           0       31       5\n",
       "21           0       33       2\n",
       "22           0       34       1\n",
       "23           0       36       2\n",
       "24           0       37       3\n",
       "25           0       39       3\n",
       "26           0       40       2\n",
       "27           0       41       5\n",
       "28           0       42       4\n",
       "29           0       44       5\n",
       "...        ...      ...     ...\n",
       "79969      942      719       1\n",
       "79970      942      720       5\n",
       "79971      942      721       3\n",
       "79972      942      723       1\n",
       "79973      942      731       4\n",
       "79974      942      738       4\n",
       "79975      942      755       2\n",
       "79976      942      762       4\n",
       "79977      942      764       3\n",
       "79978      942      784       2\n",
       "79979      942      793       3\n",
       "79980      942      795       3\n",
       "79981      942      807       4\n",
       "79982      942      815       4\n",
       "79983      942      823       4\n",
       "79984      942      824       3\n",
       "79985      942      830       2\n",
       "79986      942      839       4\n",
       "79987      942      927       5\n",
       "79988      942      940       1\n",
       "79989      942      942       5\n",
       "79990      942     1010       2\n",
       "79991      942     1027       2\n",
       "79992      942     1043       3\n",
       "79993      942     1046       2\n",
       "79994      942     1066       2\n",
       "79995      942     1073       4\n",
       "79996      942     1187       3\n",
       "79997      942     1227       3\n",
       "79998      942     1329       3\n",
       "\n",
       "[79999 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fbb5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=np.zeros((943,1682))\n",
    "for i in range(len(trainDf)):\n",
    "    R[trainDf['user_id'][i]][trainDf['item_id'][i]]=trainDf['rating'][i]\n",
    "I=(R>0)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc9173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(U,V,R,I,ahat,gamma,lamb):\n",
    "    s=0\n",
    "    k=0\n",
    "    m=0\n",
    "    for i in range(len(U)):\n",
    "        for j in range(len(V)):\n",
    "            s=s+I[i][j]*(R[i][j]-np.dot(U[i],V[j])-ahat[i][j]*gamma[i])**2\n",
    "    for i in range(len(U)):\n",
    "        k=k+LA.norm(U[i])**2\n",
    "    for i in range(len(V)):\n",
    "        m=m+LA.norm(V[i])**2\n",
    "    return s+lamb*(m+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62175959",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=[]\n",
    "V=csr_matrix((1682, 5))\n",
    "lamb=0.005\n",
    "U=csr_matrix(np.zeros((943,5))+0.5)\n",
    "gamma=np.zeros(943)+0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "722b2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.append(calculate_loss(U.toarray(),V.toarray(),R,I,a_hat,gamma,lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "368b07bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.matmul(U.toarray()[0],V.toarray().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b4787c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for j in range (20):\n",
    "    UU=np.matmul(U.toarray().T,U.toarray())\n",
    "    for i in range(1682):\n",
    "        A=csr_matrix(UU+lamb*np.identity(5))\n",
    "        B=csr_matrix(np.matmul(U.toarray().T,R[:,i])-np.matmul(U.toarray().T,np.multiply(gamma,a_hat[:,i])))\n",
    "        V[i,:] = spsolve(A, csr_matrix.transpose(B))\n",
    "    VV=np.matmul(V.toarray().T,V.toarray())\n",
    "    for u in range(943):\n",
    "        A=csr_matrix(VV+lamb*np.identity(5))\n",
    "        B=csr_matrix(np.matmul(V.toarray().T,R[u])-gamma[u]*np.matmul(V.toarray().T,a_hat[u]))\n",
    "        #B=csr_matrix(np.matmul(np.matmul(Y.toarray().T,(L_C_u_1[u]+np.identity(3000))),L_P_2[u]))\n",
    "        U[u,:] = spsolve(A, csr_matrix.transpose(B))\n",
    "        gamma[u]=(np.dot(R[u],a_hat[u])-np.dot(np.matmul(U.toarray()[u],V.toarray().T),a_hat[u]))/np.dot(a_hat[u],a_hat[u])\n",
    "    loss.append(calculate_loss(U.toarray(),V.toarray(),R,I,a_hat,gamma,lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c75f447e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[535533.6180837837, 528529.3071292449]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aa15943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(1,len(loss)+1,1),loss)\n",
    "plt.title('Cost function vs iterations')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97405d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71120384,  0.22346865,  0.39846207, ..., -0.00187911,\n",
       "        0.00666111,  0.01225199])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(U.toarray()[0],V.toarray().T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
